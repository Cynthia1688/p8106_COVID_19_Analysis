---
title: "GAM"
date: "2024-03-21"
output: 
  pdf_document:
    latex_engine: xelatex
    toc: yes
    toc_depth: 3
  header-includes:
    -\usepackage{fancyhdr}
    -\usepackage{lipsum}
    -\pagestyle{fancy}
    -\fancyhead[R]{\thepage}
    -\fancypagestyle{plain}{\pagestyle{fancy}}
---
```{r setup}
knitr::opts_chunk$set(
  collapse = TRUE, 
  warning = FALSE, 
  message = FALSE,
  fig.dim = c(10, 5),
  fig.format = "png")
```

# Load Data and Package
```{r}
library(tidyverse)
library(caret)
## Load the the training/test set & control method

# Load the training and test sets
train_data <- read.csv("./Data/train_data.csv")
test_data <- read.csv("./Data/test_data.csv")

# Load the control method
ctrl1 <- readRDS("./Data/train_control.rds")

# change variables to be factors again
train_data <- train_data %>%
  mutate(gender = as_factor(gender),
         diabetes = as_factor(diabetes),
         hypertension = as_factor(hypertension),
         vaccine = as_factor(vaccine),
         severity = as_factor(severity))

test_data <- test_data %>%
  mutate(gender = as_factor(gender),
         diabetes = as_factor(diabetes),
         hypertension = as_factor(hypertension),
         vaccine = as_factor(vaccine),
         severity = as_factor(severity))

x_train = train_data |>  select(-recovery_time)
y_train = train_data|> select(recovery_time) |>pull()

x_test = test_data |>  select(-recovery_time)
y_test = test_data|> select(recovery_time) |>pull()


```

# LASSO

```{r}
set.seed(2716)
lasso_model =  train(x = x_train, y = y_train,  method = "glmnet",
                     tuneGrid = expand.grid(alpha = 1,
                                            lambda = exp(seq(4, -4, length = 100))),
                     trControl = ctrl1,
                     preProcess = c("center", "scale"))
plot(lasso_model, xTrans = log)
# Get the index of the model with the lowest RMSE
best_model_index <- which.min(lasso_model$results$RMSE)

# Get the coefficients of the optimal model
optimal_model_coeffs <- coef(lasso_model$finalModel, s = lasso_model$results$lambda[best_model_index])

# Print the coefficients
print(optimal_model_coeffs)

lasso_pred = predict(lasso_model, x_test) 
lasso_mse = mean((y_test - lasso_pred) ^ 2)
```

# Elastic Net Model

```{r}
set.seed(2716)
enet_model = train(x = x_train, y = y_train,  method = "glmnet",
                     tuneGrid = expand.grid(alpha = seq(0, 1, length = 21),
                                            lambda = exp(seq(4, -4, length = 100))),
                     trControl = ctrl1,
                     preProcess = c("center", "scale"))
  
myCol = rainbow(25) 
myPar =
  list(superpose.symbol = list(col = myCol), 
       superpose.line = list(col = myCol))
plot(enet_model, par.settings = myPar)
# Get the index of the model with the lowest RMSE
best_model_index <- which.min(enet_model$results$RMSE)

# Get the coefficients of the optimal model
optimal_model_coeffs <- coef(enet_model$finalModel, s = enet_model$results$lambda[best_model_index])

# Print the coefficients
print(optimal_model_coeffs)

enet_pred = predict(enet_model, x_test) 
enet_mse = mean((y_test - enet_pred) ^ 2)

```

# PLS
```{r, pls, eval = FALSE, echo=FALSE}
pls_model = train(x = x_train, y = y_train,
                  method = "pls",
                  tuneGrid = data.frame(ncomp = 1:17),
                  trControl = ctrl1, preProcess = c("center", "scale"))


```
# MARS

```{r mars}
set.seed(2716)
mars_grid = expand.grid(degree = 1 : 3, nprune = seq(2, 20, by = 2))
mars_model = train(x = x_train, y = y_train, method = "earth", 
                   tuneGrid = mars_grid, trControl = ctrl1)
ggplot(mars_model)
summary(mars_model$finalModel)
## Coefficient of the MARS model
coef(mars_model$finalModel)

# Get the index of the model with the lowest RMSE
best_model_index <- which.min(mars_model$results$RMSE)

# Get the coefficients of the optimal model
optimal_model_coeffs <- coef(mars_model$finalModel, s = mars_model$results$lambda[best_model_index])

# Print the coefficients
print(optimal_model_coeffs)

mars_pred = predict(mars_model, newdata = x_test) 
mars_mse = mean((mars_pred - y_test) ^ 2)

```


# GAM

```{r GAM}
set.seed(2716)
gam_model = train(x = x_train,
                  y = y_train,
                  method = "gam",
                 #metric = "RMSE", by default
                  trControl = ctrl1)

summary(gam_model$finalModel)

# Calculate test RMSE of optimal model
gam_pred = predict(gam_model, x_test)

gam_mse = mean((gam_pred - y_test) ^ 2)

```



```{r}
set.seed(1)

x_train_A = train_data |> filter(study == "A") |> select(-recovery_time)
y_train_A = train_data|> filter(study == "A") |> select(recovery_time) |>pull()

x_test = test_data |> filter(study == "A") |> select(-recovery_time) 
y_test = test_data |> filter(study == "A") |> select(recovery_time)|>pull()

model.gam.a <- train(x = x_train_A,
                   y = y_train_A,
                   method = "gam",
                   #metric = "RMSE", by default
                   trControl = trainControl(method = "cv", number = 10))


ma_gam = model.gam.a$finalModel


x_train_B = train_data |> filter(study == "B") |> select(-recovery_time)
y_train_B = train_data|> filter(study == "B") |> select(recovery_time) |>pull()

x_test_B = test_data |> filter(study == "B") |> select(-recovery_time) 
y_test_B = test_data |> filter(study == "B") |> select(recovery_time)|>pull()

model.gam.b <- train(x = x_train_B,
                   y = y_train_B,
                   method = "gam",
                   #metric = "RMSE", by default
                   trControl = trainControl(method = "cv", number = 10))


mb_gam = model.gam.b$finalModel
summary(ma_gam)
summary(mb_gam)

```


# Random Forest

```{r}
set.seed(2716)

# long time for model training 
# save the model in model file
#control  <- trainControl(method="repeatedcv", number=10, repeats=3)
tunegrid <- expand.grid(mtry = 1:5)
#rf_model  <- train(x = x_train,
#                   y = y_train,
#                   method = "rf",
#                   trControl = ctrl1, 
#                   tuneGrid = tunegrid)

#model.rf <- train(x = x_train,
#                   y = y_train,
#                  method = "rf",
#                   #metric = "RMSE", by default
#                   trControl = trainControl(method = "cv", number = 10))


#saveRDS(rf_model, file = "./Model/model_rf.rds")
rf_model = readRDS("./Model/model_rf.rds")

print(rf_model)


rf_pred = predict(rf_model, x_test)

rf_mse = mean((rf_pred - y_test) ^ 2)

```
# Resample

```{r, resample}
resamp =
  resamples(list(lasso = lasso_model, 
                 gam = gam_model,
                 enet = enet_model,
               #  pls = pls.fit,
                 mars = mars_model,
               rf = rf_model))
summary(resamp)
bwplot(resamp, metric = "RMSE")
```

