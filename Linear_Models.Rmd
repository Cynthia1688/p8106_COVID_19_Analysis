---
title: "Linear Models"
author: "Yangyang Chen"
date: "`r Sys.Date()`"
output:
  pdf_document:
    latex_engine: xelatex
---

To gain a better understanding of the factors that predict recovery time from COVID-19 illness, a study was designed to combine three existing cohort studies that have been tracking participants for several years. The study collects recovery information through questionnaires and medical records, and leverages existing data on personal characteristics prior to the pandemic.

In this project, we predict the recovery time based on important risk factors. The training data is in “training_df”, and the test data is in “training_df”. The response is in the column “Time to recovery (tt_recovery_time)”, and other variables can be used as predictors. The variable definitions can be found in “dictionary.txt”.

First, we import the data and adjust the variable type. As we want to compare different models afterwards, we use caret.

```{r, include = FALSE, message = FALSE, warning = FALSE}

library(caret)
library(glmnet)
library(tidymodels)
library(tidyverse)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

```{r}
set.seed(2716)
# Load Data 
load("./Data/recovery.RData")
dat <- dat |> 
  mutate(gender = as_factor(gender),
         diabetes = as_factor(diabetes),
         hypertension = as_factor(hypertension),
         vaccine = as_factor(vaccine),
         severity = as_factor(severity)) |> 
  select(-id)
```

```{r}
# data splitting
data.split = initial_split(dat, prop = 0.8)
training_data = training(data.split)
testing_data = testing(data.split)

# check missing values
training_data |> is.na() |> sum()
testing_data |> is.na() |> sum()

# summary of training and testing data
training_data |> summary()
testing_data |> summary()

# training data
train.x = model.matrix(recovery_time ~ ., training_data)[, -1] 
train.y = training_data$recovery_time

# test data
test.x = model.matrix(recovery_time ~ ., testing_data)[, -1] 
test.y = testing_data$recovery_time

# cross validation
ctrl = trainControl(method = "cv", number = 10) 
```

There is no missing data in both datasets. The training dataset has 2400 observation and 16 variables, and the test dataset has 600 samples and 17 variables.

# Lasso Regression Model
```{r}
set.seed(2716)
lasso.fit = training_data |> 
  train(recovery_time ~ ., data = _, method = "glmnet",
        tuneGrid = expand.grid(
          alpha = 1,
          lambda = exp(seq(6, 0, length = 100))),
        trControl = ctrl,
        preProcess = c("center", "scale"))
plot(lasso.fit, xTrans = log)
```

The flattening in the curve occurs because the lasso regression model has reached a stable solution where no more coefficients become zero as the regularization parameter increases. At this point, further increasing the regularization parameter does not change the set of non-zero coefficients or their values, resulting in a flat region where the model's performance remains constant. This behavior indicates that the model has achieved the optimal level of sparsity, with the regularization parameter value at the start of the flat region corresponding to the desired sparse solution.

```{r}
lasso.pred = predict(lasso.fit, newdata = testing_data)
mse.lasso = mean((test.y - lasso.pred) ^ 2)
```

The selected best tuning parameter is $\lambda = 1，\alpha = 1$, and the test error (MSE) is `r mse.lasso`.

## Elastic Net Model

```{r}
set.seed(2716)
enet.fit = training_data |>
  train(recovery_time ~ ., data = _, method = "glmnet",
        tuneGrid = expand.grid(
          alpha = seq(0, 1, length = 21),
          lambda = exp(seq(8, 0, length = 100))),
        preProcess = c("center", "scale"), 
        trControl = ctrl)
myCol = rainbow(25) 
myPar =
  list(superpose.symbol = list(col = myCol), 
       superpose.line = list(col = myCol))
plot(enet.fit, par.settings = myPar)
```

The vertical line pattern in the graph is a characteristic behavior of the elastic net model. It occurs because the elastic net combines lasso and ridge regularization, which can lead to sparse solutions with some coefficients becoming exactly zero. As the regularization parameter increases, the model transitions between different sparse solutions, causing sudden drops or jumps in the cross-validation error curve. 

```{r}
enet.pred = predict(enet.fit, newdata = testing_data) 
mse.enet = mean((test.y - enet.pred) ^ 2)
```

The selected tuning parameter is $\alpha = 0$, $\lambda = 1$, and the test error (MSE) is `r mse.enet` 

## Partial Least Square

```{r}
set.seed(2716)

pls.fit = train(train.x, train.y, method = "pls",
  tuneGrid = data.frame(ncomp = 1:17),
  trControl = ctrl, preProcess = c("center", "scale"))
ggplot(pls.fit, highlight = T)
```

```{r}
pls.pred = predict(pls.fit, newdata = test.x) 
mse.pls = mean((test.y - pls.pred) ^ 2)
```

As illustrated in the plot, 11 components are included in my model, and the test error (MSE) is `r mse.pls`

The coefficients are as follows:
```{r}
coef(pls.fit$finalModel)
```

## MARS

Now, train a multivariate adaptive regression spline (MARS) model to predict the response variable.

Since there are two tuning parameters associated with the MARS model: the degree of interactions and the number of retained terms, we need to perform a grid search to identify the optimal combination of these hyperparameters that minimize prediction error.

```{r}
ctrl = trainControl(method = "cv", number = 10)
mars.grid = expand.grid(degree = 1 : 3, nprune = seq(2, 20, by = 2))
set.seed(2716)
mars.fit = train(train.x, train.y, method = "earth", tuneGrid = mars.grid, trControl = ctrl)
ggplot(mars.fit)
summary(mars.fit$finalModel)
## Coefficient of the MARS model
coef(mars.fit$finalModel)
```
The MARS model selects 12 of 27 terms, and 8 of 17 predictors. The most important variables are *bmi* (Body Mass Index; BMI = weight (in kilograms) / height (in meters) squared) and *studyB*(The study (A/B) that the participant belongs to).

To better understand the relationship between these features and outstate, we can create partial dependence plots (PDPs) for each feature individually and also an interaction PDP. To simplify, here we only present the PDP for number of full-time undergraduates *sbp*.

```{r}
pdp::partial(mars.fit, pred.var = c("bmi"), grid.resolution = 10) |> autoplot()
```
Using the final model, we can predict on the test data.

```{r}
pred.mars = predict(mars.fit, newdata = test.x) 
mse.mars = mean((pred.mars - test.y) ^ 2)
```
The test error measured by MSE using the final MARS model is `r mse.mars`

## GAM
```{r}
set.seed(2716)
gam.fit = train(train.x, train.y, method = "gam", trControl = ctrl)
summary(gam.fit$finalModel)
```

```{r}
par(mar = c(2, 2, 2, 2), mfrow = c(2, 4))
plot(gam.fit$finalModel)
```

It could be observed that certain variables (*age*, *sbp*, *ldl*) have no relationship with the *recovery_time*, *bmi*, and *height* both have a positive relationship with *recovery_time*. 

Using the final model, we can predict on the test data.

```{r}
pred.gam = predict(gam.fit, newdata = test.x) 
mse.gam = mean((pred.gam - test.y) ^ 2)
```

The test error measured by MSE using the final GAM is `r mse.gam`.

## Model Comparison

Here, we compare the CV results of different models and choose the model with the smallest median RMSE.

```{r}
resamp =
  resamples(list(lasso = lasso.fit, 
                 gam = gam.fit,
                 enet = enet.fit, 
                 pls = pls.fit,
                 mars = mars.fit))
summary(resamp)
```

Using bw-plot to compare their RMSE.
```{r}
bwplot(resamp, metric = "RMSE")
```

Hence, we selected MARS model as it has smallest RMSE.


